{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://data.csail.mit.edu/places/places365/filelist_places365-standard.tar to ../datasets/places365/filelist_places365-standard.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67498496/67498496 [03:58<00:00, 282895.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/places365/filelist_places365-standard.tar to ../datasets/places365\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      4\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      5\u001b[0m     transforms\u001b[39m.\u001b[39mResize((\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)),  \u001b[39m# Điều chỉnh kích thước ảnh về 224x224\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor(),  \u001b[39m# Chuyển đổi ảnh thành tensor\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])  \u001b[39m# Chuẩn hóa dữ liệu\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ])\n\u001b[0;32m---> 10\u001b[0m places365_dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mPlaces365(\u001b[39m'\u001b[39;49m\u001b[39m../datasets/places365\u001b[39;49m\u001b[39m'\u001b[39;49m, split\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtrain-standard\u001b[39;49m\u001b[39m'\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransform, download\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     12\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m     13\u001b[0m places365_loader \u001b[39m=\u001b[39m DataLoader(places365_dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/places365.py:83\u001b[0m, in \u001b[0;36mPlaces365.__init__\u001b[0;34m(self, root, split, small, download, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_file_list(download)\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_images()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/places365.py:153\u001b[0m, in \u001b[0;36mPlaces365.download_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe directory \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages_dir\u001b[39m}\u001b[39;00m\u001b[39m already exists. If you want to re-download or re-extract the images, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdelete the directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m file, md5 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IMAGES_META[(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmall)]\n\u001b[0;32m--> 153\u001b[0m download_and_extract_archive(urljoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_BASE_URL, file), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, md5\u001b[39m=\u001b[39;49mmd5)\n\u001b[1;32m    155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    156\u001b[0m     os\u001b[39m.\u001b[39mrename(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages_dir\u001b[39m.\u001b[39mrsplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimages_dir)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:\n\u001b[1;32m    432\u001b[0m     filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(url)\n\u001b[0;32m--> 434\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[1;32m    436\u001b[0m archive \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    437\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m{\u001b[39;00marchive\u001b[39m}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mextract_root\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:134\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    131\u001b[0m     _download_file_from_remote_location(fpath, url)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# expand redirect chain if needed\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     url \u001b[39m=\u001b[39m _get_redirect_url(url, max_hops\u001b[39m=\u001b[39;49mmax_redirect_hops)\n\u001b[1;32m    136\u001b[0m     \u001b[39m# check if file is located on Google Drive\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     file_id \u001b[39m=\u001b[39m _get_google_drive_file_id(url)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torchvision/datasets/utils.py:82\u001b[0m, in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     79\u001b[0m headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mMethod\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: USER_AGENT}\n\u001b[1;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_hops \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mwith\u001b[39;00m urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49murlopen(urllib\u001b[39m.\u001b[39;49mrequest\u001b[39m.\u001b[39;49mRequest(url, headers\u001b[39m=\u001b[39;49mheaders)) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m     83\u001b[0m         \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39murl \u001b[39m==\u001b[39m url \u001b[39mor\u001b[39;00m response\u001b[39m.\u001b[39murl \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m url\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[1;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Điều chỉnh kích thước ảnh về 224x224\n",
    "    transforms.ToTensor(),  # Chuyển đổi ảnh thành tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Chuẩn hóa dữ liệu\n",
    "])\n",
    "\n",
    "places365_dataset = datasets.Places365('../datasets/places365', split= 'train-standard', transform=transform, download= True)\n",
    "\n",
    "batch_size = 32\n",
    "places365_loader = DataLoader(places365_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
